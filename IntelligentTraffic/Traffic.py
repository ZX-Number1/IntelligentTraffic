import cv2
import numpy as np
import os
import easyocr
from ultralytics import YOLO
import collections
import pyttsx3 #å¼•å…¥èªéŸ³æ’­å ±
import tempfile
from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip
import time
import pytesseract
import threading

reader = easyocr.Reader(['en'])  # åªä½¿ç”¨è‹±æ–‡ä¾†æé«˜è­˜åˆ¥æ•ˆç‡
engine = pyttsx3.init() # åˆå§‹åŒ– pyttsx3 å¼•æ“
engine.setProperty('volume', 1) # è¨­å®šéŸ³é‡

# é¿å…èªéŸ³é‡ç–Šçš„å…¨åŸŸè®Šæ•¸
speaking = False
speaking_lock = threading.Lock() # ç¢ºä¿ speaking è®Šæ•¸çš„åŸ·è¡Œç·’å®‰å…¨

def synchronized(func):
    """åŸ·è¡Œç·’åŒæ­¥è£é£¾å™¨"""
    def wrapper(*args, **kwargs):
        with speaking_lock:
            return func(*args, **kwargs)
    return wrapper

@synchronized
def text_to_speech(text, volume=1):
    """å°‡æ–‡å­—è½‰æ›ç‚ºèªéŸ³ä¸¦æ’­æ”¾ï¼ˆé¿å…é‡ç–Šï¼‰"""
    global speaking
    if speaking:
        return # å¦‚æœæ­£åœ¨èªªè©±ï¼Œå‰‡ç›´æ¥è¿”å›
    
    speaking = True # æ¨™è¨˜ç‚ºæ­£åœ¨èªªè©±
    engine.say(text) # èªªè©±
    engine.runAndWait() # ç­‰å¾…èªªå®Œ
    speaking = False # æ¨™è¨˜ç‚ºå·²èªªå®Œ
    
def load_model(model_path='yolov8s.pt'):
    """è¼‰å…¥YOLOæ¨¡å‹"""
    try:
        model = YOLO(model_path)
        print("æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        return model
    except Exception as e:
        print(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        return None
    
def is_daytime(frame):
    """åˆ¤æ–·ç•¶å‰å ´æ™¯æ˜¯ç™½å¤©é‚„æ˜¯æ™šä¸Š"""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    brightness = np.mean(gray)
    return brightness > 80  # äº®åº¦é–¾å€¼ï¼ˆéœ€æ ¹æ“šå¯¦æ¸¬èª¿æ•´ï¼‰

def detect_traffic_light_color(roi, is_daytime_scene):
    """åµæ¸¬äº¤é€šç‡ˆçš„é¡è‰²"""
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    # å®šç¾©ç™½å¤©èˆ‡æ™šä¸Šçš„ HSV ç¯„åœ
    if is_daytime_scene:
        lower_red1, upper_red1 = np.array([0, 100, 100]), np.array([10, 255, 255])
        lower_red2, upper_red2 = np.array([170, 100, 100]), np.array([180, 255, 255])
        lower_yellow, upper_yellow = np.array([15, 120, 120]), np.array([35, 255, 255])
        lower_green, upper_green = np.array([35, 100, 100]), np.array([85, 255, 255])
    else:
        lower_red1, upper_red1 = np.array([0, 50, 50]), np.array([10, 255, 255])
        lower_red2, upper_red2 = np.array([170, 50, 50]), np.array([180, 255, 255])
        lower_yellow, upper_yellow = np.array([15, 50, 50]), np.array([35, 255, 255])
        lower_green, upper_green = np.array([30, 50, 50]), np.array([120, 255, 255])

    # å®šç¾©æ–¹å‘ç‡ˆçš„ HSV ç¯„åœ
    lower_arrow_green, upper_arrow_green = np.array([35, 100, 100]), np.array([85, 255, 255])
    lower_arrow_red, upper_arrow_red = np.array([0, 100, 100]), np.array([10, 255, 255])

    # è¨ˆç®—é¡è‰²é®ç½©
    red_mask = cv2.inRange(hsv, lower_red1, upper_red1) | cv2.inRange(hsv, lower_red2, upper_red2)
    yellow_mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
    green_mask = cv2.inRange(hsv, lower_green, upper_green)
    arrow_green_mask = cv2.inRange(hsv, lower_arrow_green, upper_arrow_green)
    arrow_red_mask = cv2.inRange(hsv, lower_arrow_red, upper_arrow_red)

    # è¨ˆç®—å€åŸŸé¢ç©
    red_area = cv2.countNonZero(red_mask)
    yellow_area = cv2.countNonZero(yellow_mask)
    green_area = cv2.countNonZero(green_mask)
    arrow_green_area = cv2.countNonZero(arrow_green_mask)
    arrow_red_area = cv2.countNonZero(arrow_red_mask)

    roi_size = roi.shape[0] * roi.shape[1]
    if red_area / roi_size < 0.05: red_area = 0
    if yellow_area / roi_size < 0.05: yellow_area = 0
    if green_area / roi_size < 0.05: green_area = 0

    # åˆ¤æ–·é¡è‰²
    if arrow_red_area > 0:
        return "Red"
    elif arrow_green_area > 0:
        return "Green"
    elif red_area > yellow_area and red_area > green_area:
        return "Red"
    elif yellow_area > red_area and yellow_area > green_area:
        return "Yellow"
    elif green_area > red_area and green_area > yellow_area:
        return "Green"
    return "Unknown"

def determine_side(roi, is_daytime_scene):
    """åˆ¤æ–·ç´…ç¶ ç‡ˆä¸Šçš„ç®­é ­æ–¹å‘ï¼ˆå·¦ã€å³æˆ–ç›´è¡Œï¼‰"""
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    # å®šç¾©ç™½å¤©èˆ‡æ™šä¸Šçš„ HSV ç¯„åœ
    if is_daytime_scene:
        lower_arrow_green, upper_arrow_green = np.array([35, 100, 100]), np.array([85, 255, 255])
        lower_arrow_red, upper_arrow_red = np.array([0, 100, 100]), np.array([10, 255, 255])
    else:
        lower_arrow_green, upper_arrow_green = np.array([35, 50, 50]), np.array([85, 255, 255])
        lower_arrow_red, upper_arrow_red = np.array([0, 50, 50]), np.array([10, 255, 255])

    # è¨ˆç®—ç®­é ­é®ç½©
    green_mask = cv2.inRange(hsv, lower_arrow_green, upper_arrow_green)
    red_mask = cv2.inRange(hsv, lower_arrow_red, upper_arrow_red)

    # ä½¿ç”¨å½¢æ…‹å­¸æ“ä½œåŠ å¼·ç®­é ­å½¢ç‹€
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
    green_mask = cv2.morphologyEx(green_mask, cv2.MORPH_CLOSE, kernel)
    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)

    # æª¢æ¸¬ç®­é ­æ–¹å‘
    contours, _ = cv2.findContours(green_mask | red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        aspect_ratio = w / float(h)  # è¨ˆç®—å¯¬é«˜æ¯”ä»¥å€åˆ†ç®­é ­å½¢ç‹€
        if 0.3 < aspect_ratio < 0.6:  # åˆ¤æ–·å¯¬é«˜æ¯”æ˜¯å¦å¯èƒ½æ˜¯ç®­é ­å½¢ç‹€
            center_x = x + w // 2
            if center_x < roi.shape[1] // 2:
                return "Left"
            else:
                return "Right"

    return "Straight"

def extract_traffic_light_number(roi, is_daytime_scene):
    """æ ¹æ“šæ™‚é–“æ¢ä»¶é¸æ“‡ OCR æ–¹æ³•ä¾†è¾¨è­˜äº¤é€šç‡ˆè™Ÿç§’æ•¸"""
    hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)

    # å®šç¾©é»ƒè‰²ç¯„åœ
    lower_yellow = np.array([15, 100, 100])
    upper_yellow = np.array([35, 255, 255])

    # éæ¿¾å‡ºé»ƒè‰²å€åŸŸ
    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)
    yellow_part = cv2.bitwise_and(roi, roi, mask=mask)

    # è½‰ç°éš
    gray = cv2.cvtColor(yellow_part, cv2.COLOR_BGR2GRAY)

    # ç›´æ–¹åœ–å‡è¡¡åŒ–ï¼Œä½¿å½±åƒäº®åº¦æ›´å‡å‹»
    gray = cv2.equalizeHist(gray)

    # é«˜æ–¯æ¨¡ç³Šå»é™¤é›œè¨Š
    blurred = cv2.GaussianBlur(gray, (3, 3), 0)

    # å˜—è©¦äºŒå€¼åŒ– (Otsuâ€™s Thresholding)
    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    if is_daytime_scene:
        # ä½¿ç”¨ EasyOCR
        result = reader.readtext(binary, allowlist="0123456789", detail=0)
    else:
        # ä½¿ç”¨ Tesseract OCR
        result = pytesseract.image_to_string(binary, config="--psm 6 digits") # éæ¿¾å‡ºæ•¸å­—
    text = ''.join(filter(str.isdigit, ''.join(result)))

    return text if text else "N/A"

def process_frame(model, frame):
    """å³æ™‚è™•ç†æ”å½±æ©Ÿå½±åƒï¼Œä¸¦å›å‚³ YOLO åµæ¸¬çµæœ"""
    results = model(frame)
    detections = []
    
    # ç”¨æ–¼é¿å…é‡è¤‡èªéŸ³æ’­å ±
    last_traffic_color = "Unknown"
    last_truck_alert = False
    last_countdown_alert = False
    result_queue = collections.deque(maxlen=5)

    is_daytime_scene = is_daytime(frame)
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf)
            class_id = int(box.cls)
                
            if conf > 0.3:
                if class_id == 7:  # Assuming class 7 is for trucks, this can change based on your model's class IDs
                    box_color = (0, 0, 255)  # ç´…è‰²æ¡†
                    label = f"Truck {conf:.2f}"
                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, box_color, 2)
                    cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)  # ç¹ªè£½ç´…è‰²æ¡†
                        
                    if not last_truck_alert:  # Ensure the alert is only triggered once for each truck detection
                        text_to_speech("å°å¿ƒå¤§å‹è»Š", volume=1)
                        last_truck_alert = True  # Set the flag to True after alerting
                    
            if conf > 0.3 and class_id in [9, 10, 11]:  # 9: æ™®é€šç‡ˆ, 10: å·¦ç®­é ­, 11: å³ç®­é ­
                traffic_light_roi = frame[y1:y2, x1:x2]
                if traffic_light_roi.size > 0:
                    color = detect_traffic_light_color(traffic_light_roi, is_daytime_scene)
                    side = determine_side(traffic_light_roi, is_daytime_scene)  # åˆ¤æ–·å·¦å³é‚Š

                    result_queue.append((color, side))
                    recent_results = [r[0] for r in result_queue if r[1] == side]
                    if len(recent_results) > 2:  
                        if recent_results.count("Red") > 2:
                            color = "Red"
                        elif recent_results.count("Yellow") > 2:
                            color = "Yellow"
                        elif recent_results.count("Green") > 3:
                            color = "Green"
                        else:
                            color = "Unknown"
                    else:
                        color = "Unknown"  # å¦‚æœæ²’æœ‰è¶³å¤ æ•¸æ“šï¼Œå‰‡ä¸åˆ¤å®š
                        
                    box_color = (0, 255, 0) if "Green" in color else \
                                    (0, 255, 255) if "Yellow" in color else \
                                    (0, 0, 255) if "Red" in color else \
                                    (255, 255, 255)
                    label = f"{color} {side} {conf:.2f}"
                    cv2.putText(frame, label, (x1, y1 - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, box_color, 2)

                    countdown_number = extract_traffic_light_number(traffic_light_roi, is_daytime_scene)

                    if color == "Unknown" and color == last_traffic_color:
                        text_to_speech("æœªåµæ¸¬åˆ°ï¼Œè«‹æ³¨æ„å‘¨é­è»Šè¼›", volume=0.2)
                    elif color  != "Unknown" and color != last_traffic_color:
                        if color == "Red":
                            text_to_speech("ä¸å¯é€šè¡Œ", volume=1)
                            last_traffic_color = color
                        elif color == "Yellow":
                            text_to_speech("ä¸å¯é€šè¡Œ", volume=1)
                            last_traffic_color = color
                        elif last_truck_alert: #å…ˆåˆ¤æ–·å¡è»Šå†åˆ¤æ–·ç¶ ç‡ˆ
                            text_to_speech("å¯é€šè¡Œï¼Œæ³¨æ„å¤§å‹è»Š", volume=1)
                            last_traffic_color = color
                        elif color == "Green":
                            text_to_speech("å¯é€šè¡Œ", volume=1)
                            last_traffic_color = color
                        elif color == "Unknown":
                            text_to_speech("æœªåµæ¸¬åˆ°ï¼Œè«‹æ³¨æ„å‘¨é­è»Šè¼›", volume=0.2)
                            last_traffic_color = color
                        
                    # æ·»åŠ ä¸€å€‹è¨ˆæ•¸å™¨ä¾†è¨˜éŒ„ä½æ–¼ 20 ç§’çš„æ¬¡æ•¸
                countdown_below_20_count = 0
                    # å€’æ•¸æ™‚é–“ä½æ–¼ 20 ç§’æ™‚æ’­å ±ä¸€æ¬¡
                try:
                    if countdown_number.isdigit():  # ç¢ºä¿ countdown_number æ˜¯æœ‰æ•ˆæ•¸å­—
                        countdown_value = int(countdown_number)
                    else:
                        countdown_value = None  # è‹¥ä¸æ˜¯æ•¸å­—ï¼Œè¨­å®šç‚º None

                    if countdown_value is not None and countdown_value < 20 and not last_countdown_alert:
                        print(f"âš ï¸ æ’­å ±æé†’ï¼šç§’æ•¸ {countdown_value} ä½æ–¼ 20 ç§’")  
                        text_to_speech("è«‹æ³¨æ„ç¾åœ¨ç§’æ•¸ä½æ–¼20ç§’")
                        last_countdown_alert = True  

                    elif countdown_value is not None and countdown_value >= 30 and last_countdown_alert:
                        print(f"ğŸ”„ é‡ç½® last_countdown_alertï¼ˆç•¶å‰ç§’æ•¸ {countdown_value}ï¼‰")  
                        last_countdown_alert = False
                except ValueError:
                    countdown_value = None  # è§£æéŒ¯èª¤å‰‡å¿½ç•¥

                    # Display the countdown number
                cv2.putText(frame, f"{countdown_number}", (x1, y2 + 30),
                                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                        
                    # ç¹ªè£½æ¡†
                cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 2)

    return frame, detections

if __name__ == "__main__":
    model_path =  "yolov8s.pt"
    model = YOLO(model_path)
    
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼Œè«‹ä½¿ç”¨ `process_frame(model, frame)` ä¾†å³æ™‚è™•ç†å½±åƒã€‚")


